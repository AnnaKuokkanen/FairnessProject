{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPN7EQj-P5GZ"
      },
      "source": [
        "## Project 3\n",
        "\n",
        "Dataset: COMPAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U8B_biHyP5Gb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K6QvYtDP5Gc",
        "outputId": "948ad49a-494d-400e-cff2-e5bb780afc4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7214, 53)\n",
            "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
            "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
            "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
            "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
            "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
            "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
            "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
            "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
            "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
            "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
            "       'decile_score.1', 'score_text', 'screening_date',\n",
            "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
            "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
            "       'start', 'end', 'event', 'two_year_recid'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
        "print(df.shape)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T7gLaMpP5Gd"
      },
      "source": [
        "We will first fit a model predicting if the person will reoffend in the next two years. We could use a classifier for this.\n",
        "\n",
        "Next steps:\n",
        "\n",
        "* look at the data for bias\n",
        "* build a classifier\n",
        "\n",
        "Sensitive variables: race, sex\n",
        "\n",
        "Target variable: two_year_recid\n",
        "\n",
        "Features: age/age_cat, juv_fel_count, juv_misd_count, juv_other_count, priors_count, c_charge_degree, score_text, days_b_screening_arrest, decile_score, length_of_stay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTcqIQEpP5Gd"
      },
      "source": [
        "## Twin test\n",
        "\n",
        "Feature: prior convictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3GY5OdP5Ge",
        "outputId": "2eb7401e-13ed-4f92-d736-5c8b8dec68b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-9846e302070a>:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"age_cat\"] = df[\"age_cat\"].replace({\"Less than 25\": 0, \"25 - 45\": 1, \"Greater than 45\": 2})\n"
          ]
        }
      ],
      "source": [
        "df = df[[\"race\", \"sex\", \"age_cat\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\", \"c_charge_degree\", \"two_year_recid\"]]\n",
        "\n",
        "df = df[(df[\"c_charge_degree\"] != 'O')]\n",
        "\n",
        "# sum 1-20 together\n",
        "df[\"juv_fel_count\"] = np.where(df[\"juv_fel_count\"] == 0, 0, 1)\n",
        "df[\"juv_misd_count\"] = np.where(df[\"juv_misd_count\"] == 0, 0, 1)\n",
        "df[\"juv_other_count\"] = np.where(df[\"juv_other_count\"] == 0, 0, 1)\n",
        "df[\"priors_count\"]\n",
        "\n",
        "df.loc[(df['priors_count'] >= 0) & (df['priors_count'] <= 10), 'priors_count'] = 0\n",
        "df.loc[(df['priors_count'] > 10) & (df['priors_count'] <= 20), 'priors_count'] = 1\n",
        "df.loc[(df['priors_count'] > 20), 'priors_count'] = 2\n",
        "\n",
        "df[\"c_charge_degree\"] = np.where(df[\"c_charge_degree\"] == \"M\", 0, 1)\n",
        "df[\"age_cat\"] = df[\"age_cat\"].replace({\"Less than 25\": 0, \"25 - 45\": 1, \"Greater than 45\": 2})\n",
        "df[\"race\"] = df[\"race\"].replace({\"Asian\": \"Minority\", \"Native American\": \"Minority\", \"Other\": \"Minority\"})\n",
        "\n",
        "df[\"sensitive\"] = df.apply(lambda x: x[\"race\"][0] + x[\"sex\"][0], axis=1)\n",
        "\n",
        "df.head()\n",
        "df.to_csv(\"data_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "sq0EA1OKP5Ge"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def individual_fairness(df, charge_column,outcome_column):\n",
        "    \"\"\"\n",
        "    Compute probabilities for individual fairness based on the sensitive attribute and a specified charge column.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_path : str\n",
        "        Path to the CSV file containing the data.\n",
        "    charge_column : str\n",
        "        The column name corresponding to the charge degree.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        A DataFrame with computed probabilities for individual fairness analysis.\n",
        "    \"\"\"\n",
        "    # Read the dataset\n",
        "    # Group by sensitive attribute, charge degree, and recidivism outcome\n",
        "    df_count = df.groupby([\"sensitive\", charge_column, outcome_column]).agg(\n",
        "        count=('sensitive', 'count')).reset_index()\n",
        "\n",
        "    # Sum counts for each sensitive attribute and charge degree\n",
        "    df_sum = df_count.groupby([\"sensitive\", charge_column]).agg(\n",
        "        sum=('count', 'sum')).reset_index()\n",
        "\n",
        "    # Merge the count and sum dataframes\n",
        "    df_summary = pd.merge(df_count, df_sum, on=[\"sensitive\", charge_column])\n",
        "\n",
        "    # Calculate probabilities\n",
        "    df_summary[\"prob\"] = df_summary[\"count\"] / df_summary[\"sum\"]\n",
        "\n",
        "    # Print the summary\n",
        "    print(df_summary)\n",
        "\n",
        "    return df_summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function with the appropriate file path and charge column\n",
        "df = pd.read_csv('data_clean.csv')\n",
        "\n",
        "df_summary = individual_fairness(df, \"c_charge_degree\", 'two_year_recid')\n",
        "#df_summary = individual_fairness(df, \"priors_count\", 'two_year_recid')\n",
        "#df_summary = individual_fairness(df, \"age_cat\" , 'two_year_recid')\n",
        "#df_summary = individual_fairness(df, \"juv_fel_count\" , 'two_year_recid')\n",
        "#df_summary = individual_fairness(df, \"c_charge_degree\", 'two_year_recid')\n",
        "#df_summary = individual_fairness(df, \"juv_other_count\", 'two_year_recid')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWsZjYzPsmxS",
        "outputId": "b298a1f4-b00b-48f9-f2a8-c90b3e2fc833"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sensitive  c_charge_degree  two_year_recid  count   sum      prob\n",
            "0         AF                0               0    157   229  0.685590\n",
            "1         AF                0               1     72   229  0.314410\n",
            "2         AF                1               0    248   423  0.586288\n",
            "3         AF                1               1    175   423  0.413712\n",
            "4         AM                0               0    470   920  0.510870\n",
            "5         AM                0               1    450   920  0.489130\n",
            "6         AM                1               0    920  2124  0.433145\n",
            "7         AM                1               1   1204  2124  0.566855\n",
            "8         CF                0               0    190   259  0.733591\n",
            "9         CF                0               1     69   259  0.266409\n",
            "10        CF                1               0    178   308  0.577922\n",
            "11        CF                1               1    130   308  0.422078\n",
            "12        CM                0               0    459   715  0.641958\n",
            "13        CM                0               1    256   715  0.358042\n",
            "14        CM                1               0    661  1172  0.563993\n",
            "15        CM                1               1    511  1172  0.436007\n",
            "16        HF                0               0     38    50  0.760000\n",
            "17        HF                0               1     12    50  0.240000\n",
            "18        HF                1               0     32    53  0.603774\n",
            "19        HF                1               1     21    53  0.396226\n",
            "20        HM                0               0    151   218  0.692661\n",
            "21        HM                0               1     67   218  0.307339\n",
            "22        HM                1               0    184   316  0.582278\n",
            "23        HM                1               1    132   316  0.417722\n",
            "24        MF                0               0     22    28  0.785714\n",
            "25        MF                0               1      6    28  0.214286\n",
            "26        MF                1               0     32    45  0.711111\n",
            "27        MF                1               1     13    45  0.288889\n",
            "28        MM                0               0     92   129  0.713178\n",
            "29        MM                0               1     37   129  0.286822\n",
            "30        MM                1               0    129   225  0.573333\n",
            "31        MM                1               1     96   225  0.426667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxwTwzNQ_u4c",
        "outputId": "a3ee7eaf-202e-4a9f-e87e-0e7ac5505865"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7214, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1c6QaARP5Gf"
      },
      "source": [
        "## Group fairness\n",
        "\n",
        "only sensitive data as prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "KQ_iFvZPP5Gf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def group_fairness(df, sensitive_column, outcome_column):\n",
        "    \"\"\"\n",
        "    Compute probabilities for group fairness based on a sensitive attribute.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_path : str\n",
        "        Path to the CSV file containing the data.\n",
        "    sensitive_column : str\n",
        "        The name of the column representing the sensitive attribute.\n",
        "    outcome_column : str\n",
        "        The name of the column representing the outcome (e.g., recidivism).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        A DataFrame with computed probabilities for group fairness analysis.\n",
        "    \"\"\"\n",
        "    # Group by sensitive attribute and outcome\n",
        "    df_count = df.groupby([sensitive_column, outcome_column]).agg(\n",
        "        count=('sensitive', 'count')).reset_index()\n",
        "\n",
        "    # Sum counts for each sensitive attribute\n",
        "    df_sum = df_count.groupby([sensitive_column]).agg(\n",
        "        sum=('count', 'sum')).reset_index()\n",
        "\n",
        "    # Merge the count and sum dataframes\n",
        "    df_summary = pd.merge(df_count, df_sum, on=[sensitive_column])\n",
        "\n",
        "    # Calculate probabilities\n",
        "    df_summary[\"prob\"] = df_summary[\"count\"] / df_summary[\"sum\"]\n",
        "\n",
        "    # Print the summary\n",
        "    print(df_summary)\n",
        "\n",
        "    return df_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data_clean.csv')\n",
        "df_summary = group_fairness(df,\"sensitive\",'two_year_recid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBQ3KWJCqGWk",
        "outputId": "c8b631ae-7485-4a99-c7b5-c7ed72d2a9b7"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sensitive  two_year_recid  count   sum      prob\n",
            "0         AF               0    405   652  0.621166\n",
            "1         AF               1    247   652  0.378834\n",
            "2         AM               0   1390  3044  0.456636\n",
            "3         AM               1   1654  3044  0.543364\n",
            "4         CF               0    368   567  0.649030\n",
            "5         CF               1    199   567  0.350970\n",
            "6         CM               0   1120  1887  0.593535\n",
            "7         CM               1    767  1887  0.406465\n",
            "8         HF               0     70   103  0.679612\n",
            "9         HF               1     33   103  0.320388\n",
            "10        HM               0    335   534  0.627341\n",
            "11        HM               1    199   534  0.372659\n",
            "12        MF               0     54    73  0.739726\n",
            "13        MF               1     19    73  0.260274\n",
            "14        MM               0    221   354  0.624294\n",
            "15        MM               1    133   354  0.375706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMSrDBSYP5Gg"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj2zokuJP5Gg",
        "outputId": "79420f92-b336-4b26-d15a-b0e08db7dc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.80      0.72       823\n",
            "           1       0.62      0.42      0.50       620\n",
            "\n",
            "    accuracy                           0.64      1443\n",
            "   macro avg       0.63      0.61      0.61      1443\n",
            "weighted avg       0.64      0.64      0.63      1443\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"data_clean.csv\")\n",
        "\n",
        "# Select relevant columns for features and target\n",
        "features = df.iloc[:, 3:-2]\n",
        "\n",
        "target = df['two_year_recid']\n",
        "\n",
        "# Handle missing values if any\n",
        "features = features.fillna(0)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "#model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Train an XGBoost model (replacing Logistic Regression)\n",
        "#model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_test_pred = model.predict(X_test)\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_test_pred)\n",
        "report = classification_report(y_test, y_test_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = X_test.copy()\n",
        "df_test['two_year_recid_actual'] = y_test\n",
        "df_test['two_year_recid_predicted'] = y_test_pred\n",
        "df_test[\"sensitive\"] = df.loc[df_test.index.values, \"sensitive\"]\n",
        "df_test[\"data_split\"] = \"test\"\n",
        "\n",
        "# Create a DataFrame for the training set\n",
        "df_train = X_train.copy()\n",
        "df_train['two_year_recid_actual'] = y_train\n",
        "df_train['two_year_recid_predicted'] = y_train_pred\n",
        "df_train[\"sensitive\"] = df.loc[df_train.index.values, \"sensitive\"]\n",
        "df_train[\"data_split\"] = \"train\"\n",
        "\n",
        "# Concatenate train and test results\n",
        "all_results = pd.concat([df_train, df_test], ignore_index=True)"
      ],
      "metadata": {
        "id": "Sj6WzxvzxUk-"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_results.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5zHofwZDHVL",
        "outputId": "8f085292-0849-4bcd-ca16-59770c922811"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7214, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVC9hMlGP5Gg",
        "outputId": "08e63ee2-dde3-4113-8fc5-ae97a90dfcae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sensitive  c_charge_degree  two_year_recid_predicted  count   sum      prob\n",
            "0         AF                0                         0    207   229  0.903930\n",
            "1         AF                0                         1     22   229  0.096070\n",
            "2         AF                1                         0    270   423  0.638298\n",
            "3         AF                1                         1    153   423  0.361702\n",
            "4         AM                0                         0    740   920  0.804348\n",
            "5         AM                0                         1    180   920  0.195652\n",
            "6         AM                1                         0   1062  2124  0.500000\n",
            "7         AM                1                         1   1062  2124  0.500000\n",
            "8         CF                0                         0    244   259  0.942085\n",
            "9         CF                0                         1     15   259  0.057915\n",
            "10        CF                1                         0    237   308  0.769481\n",
            "11        CF                1                         1     71   308  0.230519\n",
            "12        CM                0                         0    647   715  0.904895\n",
            "13        CM                0                         1     68   715  0.095105\n",
            "14        CM                1                         0    848  1172  0.723549\n",
            "15        CM                1                         1    324  1172  0.276451\n",
            "16        HF                0                         0     46    50  0.920000\n",
            "17        HF                0                         1      4    50  0.080000\n",
            "18        HF                1                         0     43    53  0.811321\n",
            "19        HF                1                         1     10    53  0.188679\n",
            "20        HM                0                         0    206   218  0.944954\n",
            "21        HM                0                         1     12   218  0.055046\n",
            "22        HM                1                         0    201   316  0.636076\n",
            "23        HM                1                         1    115   316  0.363924\n",
            "24        MF                0                         0     28    28  1.000000\n",
            "25        MF                1                         0     35    45  0.777778\n",
            "26        MF                1                         1     10    45  0.222222\n",
            "27        MM                0                         0    123   129  0.953488\n",
            "28        MM                0                         1      6   129  0.046512\n",
            "29        MM                1                         0    159   225  0.706667\n",
            "30        MM                1                         1     66   225  0.293333\n"
          ]
        }
      ],
      "source": [
        "result = individual_fairness(all_results, \"c_charge_degree\", 'two_year_recid_predicted')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary = group_fairness(df_test,\"sensitive\",'two_year_recid_predicted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9qt0IlxZGl6",
        "outputId": "923d0502-6fea-407c-a256-459ddcf745ac"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sensitive  two_year_recid_predicted  count  sum      prob\n",
            "0         AF                         0     80  107  0.747664\n",
            "1         AF                         1     27  107  0.252336\n",
            "2         AM                         0    362  624  0.580128\n",
            "3         AM                         1    262  624  0.419872\n",
            "4         CF                         0     88  107  0.822430\n",
            "5         CF                         1     19  107  0.177570\n",
            "6         CM                         0    322  398  0.809045\n",
            "7         CM                         1     76  398  0.190955\n",
            "8         HF                         0     17   20  0.850000\n",
            "9         HF                         1      3   20  0.150000\n",
            "10        HM                         0     72   97  0.742268\n",
            "11        HM                         1     25   97  0.257732\n",
            "12        MF                         0     14   16  0.875000\n",
            "13        MF                         1      2   16  0.125000\n",
            "14        MM                         0     60   74  0.810811\n",
            "15        MM                         1     14   74  0.189189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoqaUCVuP5Gh"
      },
      "source": [
        "Note! When looking at c_charge_degree we found that the model was more biased toward African-American males than Caucasian males (prediction for AM 0.5 vs. CM 0.27; in data AM 0.56 and CM 0.43)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv(\"data_clean.csv\")\n",
        "\n",
        "# Select relevant columns for features and target\n",
        "features = df.iloc[:, 3:-2]\n",
        "target = df['two_year_recid']\n",
        "\n",
        "# Handle missing values if any\n",
        "features = features.fillna(0)\n",
        "\n",
        "# Convert target to categorical if necessary\n",
        "# (Assuming binary classification: 0 and 1)\n",
        "target = to_categorical(target, num_classes=2)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build a simple neural network\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=features.shape[1], activation='relu'),  # Hidden layer with 64 neurons\n",
        "    Dense(32, activation='relu'),  # Hidden layer with 32 neurons\n",
        "    Dense(2, activation='softmax')  # Output layer (2 classes)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "y_test_classes = y_test.argmax(axis=1)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "report = classification_report(y_test_classes, y_pred_classes)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "j2gkhyzb3QkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = X_test.copy()\n",
        "df_test['two_year_recid_actual'] = y_test.argmax(axis=1)\n",
        "df_test['two_year_recid_predicted'] = y_pred.argmax(axis=1)\n",
        "\n",
        "df_test[\"sensitive\"] = df.loc[df_test.index.values, \"sensitive\"]"
      ],
      "metadata": {
        "id": "mRi_z5zY3WRE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
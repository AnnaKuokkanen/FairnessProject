{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPN7EQj-P5GZ"
      },
      "source": [
        "## Project 3\n",
        "\n",
        "Dataset: COMPAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U8B_biHyP5Gb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K6QvYtDP5Gc",
        "outputId": "1efcb7d4-02ef-48ce-fb72-875cc984d844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7214, 53)\n",
            "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
            "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
            "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
            "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
            "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
            "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
            "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
            "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
            "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
            "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
            "       'decile_score.1', 'score_text', 'screening_date',\n",
            "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
            "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
            "       'start', 'end', 'event', 'two_year_recid'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
        "print(df.shape)\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T7gLaMpP5Gd"
      },
      "source": [
        "We will first fit a model predicting if the person will reoffend in the next two years. We could use a classifier for this.\n",
        "\n",
        "Next steps:\n",
        "\n",
        "* look at the data for bias\n",
        "* build a classifier\n",
        "\n",
        "Sensitive variables: race, sex\n",
        "\n",
        "Target variable: two_year_recid\n",
        "\n",
        "Features: age/age_cat, juv_fel_count, juv_misd_count, juv_other_count, priors_count, c_charge_degree, score_text, days_b_screening_arrest, decile_score, length_of_stay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTcqIQEpP5Gd"
      },
      "source": [
        "## Twin test\n",
        "\n",
        "Feature: prior convictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3GY5OdP5Ge",
        "outputId": "feb0987a-0b05-4459-82bb-758b3301ae87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9846e302070a>:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"age_cat\"] = df[\"age_cat\"].replace({\"Less than 25\": 0, \"25 - 45\": 1, \"Greater than 45\": 2})\n"
          ]
        }
      ],
      "source": [
        "df = df[[\"race\", \"sex\", \"age_cat\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\", \"c_charge_degree\", \"two_year_recid\"]]\n",
        "\n",
        "df = df[(df[\"c_charge_degree\"] != 'O')]\n",
        "\n",
        "# sum 1-20 together\n",
        "df[\"juv_fel_count\"] = np.where(df[\"juv_fel_count\"] == 0, 0, 1)\n",
        "df[\"juv_misd_count\"] = np.where(df[\"juv_misd_count\"] == 0, 0, 1)\n",
        "df[\"juv_other_count\"] = np.where(df[\"juv_other_count\"] == 0, 0, 1)\n",
        "df[\"priors_count\"]\n",
        "\n",
        "df.loc[(df['priors_count'] >= 0) & (df['priors_count'] <= 10), 'priors_count'] = 0\n",
        "df.loc[(df['priors_count'] > 10) & (df['priors_count'] <= 20), 'priors_count'] = 1\n",
        "df.loc[(df['priors_count'] > 20), 'priors_count'] = 2\n",
        "\n",
        "df[\"c_charge_degree\"] = np.where(df[\"c_charge_degree\"] == \"M\", 0, 1)\n",
        "df[\"age_cat\"] = df[\"age_cat\"].replace({\"Less than 25\": 0, \"25 - 45\": 1, \"Greater than 45\": 2})\n",
        "df[\"race\"] = df[\"race\"].replace({\"Asian\": \"Minority\", \"Native American\": \"Minority\", \"Other\": \"Minority\"})\n",
        "\n",
        "df[\"sensitive\"] = df.apply(lambda x: x[\"race\"][0] + x[\"sex\"][0], axis=1)\n",
        "\n",
        "df.head()\n",
        "df.to_csv(\"data_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq0EA1OKP5Ge",
        "outputId": "6c798b0d-225d-4593-f6be-3dc7df44008f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sensitive  c_charge_degree  two_year_recid  count   sum      prob\n",
            "0         AF                0               0    157   229  0.685590\n",
            "1         AF                0               1     72   229  0.314410\n",
            "2         AF                1               0    248   423  0.586288\n",
            "3         AF                1               1    175   423  0.413712\n",
            "4         AM                0               0    470   920  0.510870\n",
            "5         AM                0               1    450   920  0.489130\n",
            "6         AM                1               0    920  2124  0.433145\n",
            "7         AM                1               1   1204  2124  0.566855\n",
            "8         CF                0               0    190   259  0.733591\n",
            "9         CF                0               1     69   259  0.266409\n",
            "10        CF                1               0    178   308  0.577922\n",
            "11        CF                1               1    130   308  0.422078\n",
            "12        CM                0               0    459   715  0.641958\n",
            "13        CM                0               1    256   715  0.358042\n",
            "14        CM                1               0    661  1172  0.563993\n",
            "15        CM                1               1    511  1172  0.436007\n",
            "16        HF                0               0     38    50  0.760000\n",
            "17        HF                0               1     12    50  0.240000\n",
            "18        HF                1               0     32    53  0.603774\n",
            "19        HF                1               1     21    53  0.396226\n",
            "20        HM                0               0    151   218  0.692661\n",
            "21        HM                0               1     67   218  0.307339\n",
            "22        HM                1               0    184   316  0.582278\n",
            "23        HM                1               1    132   316  0.417722\n",
            "24        MF                0               0     22    28  0.785714\n",
            "25        MF                0               1      6    28  0.214286\n",
            "26        MF                1               0     32    45  0.711111\n",
            "27        MF                1               1     13    45  0.288889\n",
            "28        MM                0               0     92   129  0.713178\n",
            "29        MM                0               1     37   129  0.286822\n",
            "30        MM                1               0    129   225  0.573333\n",
            "31        MM                1               1     96   225  0.426667\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"data_clean.csv\")\n",
        "\n",
        "df_count = df.groupby([\"sensitive\", \"c_charge_degree\", \"two_year_recid\"]).agg(\n",
        "    count=('race', 'count')).reset_index()\n",
        "\n",
        "df_sum = df_count.groupby([\"sensitive\", \"c_charge_degree\"]).agg(\n",
        "    sum=('count', 'sum')).reset_index()\n",
        "\n",
        "df_summary = pd.merge(df_count, df_sum, on=[\"sensitive\", \"c_charge_degree\"])\n",
        "\n",
        "df_summary[\"prob\"] = df_summary[\"count\"] / df_summary[\"sum\"]\n",
        "print(df_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1c6QaARP5Gf"
      },
      "source": [
        "## Group fairness\n",
        "\n",
        "only sensitive data as prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ_iFvZPP5Gf",
        "outputId": "51565ced-b1ed-4ad9-e093-211d204c00b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sensitive  two_year_recid  count   sum      prob\n",
            "0         AF               0    405   652  0.621166\n",
            "1         AF               1    247   652  0.378834\n",
            "2         AM               0   1390  3044  0.456636\n",
            "3         AM               1   1654  3044  0.543364\n",
            "4         CF               0    368   567  0.649030\n",
            "5         CF               1    199   567  0.350970\n",
            "6         CM               0   1120  1887  0.593535\n",
            "7         CM               1    767  1887  0.406465\n",
            "8         HF               0     70   103  0.679612\n",
            "9         HF               1     33   103  0.320388\n",
            "10        HM               0    335   534  0.627341\n",
            "11        HM               1    199   534  0.372659\n",
            "12        MF               0     54    73  0.739726\n",
            "13        MF               1     19    73  0.260274\n",
            "14        MM               0    221   354  0.624294\n",
            "15        MM               1    133   354  0.375706\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"data_clean.csv\")\n",
        "\n",
        "df_count = df.groupby([\"sensitive\", \"two_year_recid\"]).agg(\n",
        "    count=('race', 'count')).reset_index()\n",
        "\n",
        "df_sum = df_count.groupby([\"sensitive\"]).agg(\n",
        "    sum=('count', 'sum')).reset_index()\n",
        "\n",
        "df_summary = pd.merge(df_count, df_sum, on=[\"sensitive\"])\n",
        "\n",
        "df_summary[\"prob\"] = df_summary[\"count\"] / df_summary[\"sum\"]\n",
        "print(df_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMSrDBSYP5Gg"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj2zokuJP5Gg",
        "outputId": "17a71404-f655-4f02-c8c5-922501d58ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [08:53:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.80      0.72       823\n",
            "           1       0.61      0.42      0.50       620\n",
            "\n",
            "    accuracy                           0.64      1443\n",
            "   macro avg       0.63      0.61      0.61      1443\n",
            "weighted avg       0.63      0.64      0.62      1443\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"data_clean.csv\")\n",
        "\n",
        "# Select relevant columns for features and target\n",
        "features = df.iloc[:, 3:-2]\n",
        "\n",
        "target = df['two_year_recid']\n",
        "\n",
        "# Handle missing values if any\n",
        "features = features.fillna(0)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "#model = LogisticRegression(max_iter=1000)\n",
        "#model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Train an XGBoost model (replacing Logistic Regression)\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "df = pd.read_csv(\"data_clean.csv\")\n",
        "\n",
        "# Select relevant columns for features and target\n",
        "features = df.iloc[:, 3:-2]\n",
        "target = df['two_year_recid']\n",
        "\n",
        "# Handle missing values if any\n",
        "features = features.fillna(0)\n",
        "\n",
        "# Convert target to categorical if necessary\n",
        "# (Assuming binary classification: 0 and 1)\n",
        "target = to_categorical(target, num_classes=2)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build a simple neural network\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=features.shape[1], activation='relu'),  # Hidden layer with 64 neurons\n",
        "    Dense(32, activation='relu'),  # Hidden layer with 32 neurons\n",
        "    Dense(2, activation='softmax')  # Output layer (2 classes)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "y_test_classes = y_test.argmax(axis=1)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "report = classification_report(y_test_classes, y_pred_classes)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epBpgtUrSRYc",
        "outputId": "ee68912a-be76-4c7e-dc8e-9c2dc8e65297"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6031 - loss: 0.6666 - val_accuracy: 0.6149 - val_loss: 0.6508\n",
            "Epoch 2/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6068 - loss: 0.6531 - val_accuracy: 0.6119 - val_loss: 0.6499\n",
            "Epoch 3/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6162 - loss: 0.6446 - val_accuracy: 0.6129 - val_loss: 0.6515\n",
            "Epoch 4/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6264 - loss: 0.6463 - val_accuracy: 0.6109 - val_loss: 0.6509\n",
            "Epoch 5/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6276 - loss: 0.6475 - val_accuracy: 0.6119 - val_loss: 0.6512\n",
            "Epoch 6/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6277 - loss: 0.6392 - val_accuracy: 0.6030 - val_loss: 0.6604\n",
            "Epoch 7/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6208 - loss: 0.6340 - val_accuracy: 0.6129 - val_loss: 0.6507\n",
            "Epoch 8/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6340 - loss: 0.6374 - val_accuracy: 0.6109 - val_loss: 0.6506\n",
            "Epoch 9/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.6411 - val_accuracy: 0.6109 - val_loss: 0.6529\n",
            "Epoch 10/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6366 - loss: 0.6376 - val_accuracy: 0.6139 - val_loss: 0.6512\n",
            "Epoch 11/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6099 - loss: 0.6477 - val_accuracy: 0.6059 - val_loss: 0.6556\n",
            "Epoch 12/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6172 - loss: 0.6458 - val_accuracy: 0.6139 - val_loss: 0.6516\n",
            "Epoch 13/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6287 - loss: 0.6395 - val_accuracy: 0.6139 - val_loss: 0.6507\n",
            "Epoch 14/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6231 - loss: 0.6354 - val_accuracy: 0.6139 - val_loss: 0.6504\n",
            "Epoch 15/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6196 - loss: 0.6462 - val_accuracy: 0.6129 - val_loss: 0.6514\n",
            "Epoch 16/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6354 - loss: 0.6385 - val_accuracy: 0.6109 - val_loss: 0.6526\n",
            "Epoch 17/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6162 - loss: 0.6377 - val_accuracy: 0.6139 - val_loss: 0.6513\n",
            "Epoch 18/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6202 - loss: 0.6434 - val_accuracy: 0.6119 - val_loss: 0.6524\n",
            "Epoch 19/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6178 - loss: 0.6447 - val_accuracy: 0.6129 - val_loss: 0.6518\n",
            "Epoch 20/20\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6147 - loss: 0.6482 - val_accuracy: 0.6129 - val_loss: 0.6534\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Accuracy: 0.63\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.90      0.73      1207\n",
            "           1       0.71      0.29      0.41       958\n",
            "\n",
            "    accuracy                           0.63      2165\n",
            "   macro avg       0.66      0.60      0.57      2165\n",
            "weighted avg       0.66      0.63      0.59      2165\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "97P1lwhtP5Gg"
      },
      "outputs": [],
      "source": [
        "df_test = X_test.copy()\n",
        "df_test['two_year_recid_actual'] = y_test\n",
        "df_test['two_year_recid_predicted'] = y_pred\n",
        "\n",
        "df_test[\"sensitive\"] = df.loc[df_test.index.values, \"sensitive\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVC9hMlGP5Gg",
        "outputId": "2e17861f-34ab-49b4-c023-18c5d5b17458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sensitive  c_charge_degree  two_year_recid_predicted  count  sum      prob\n",
            "0         AF                0                         0     59   65  0.907692\n",
            "1         AF                0                         1      6   65  0.092308\n",
            "2         AF                1                         0     73  109  0.669725\n",
            "3         AF                1                         1     36  109  0.330275\n",
            "4         AM                0                         0    213  272  0.783088\n",
            "5         AM                0                         1     59  272  0.216912\n",
            "6         AM                1                         0    331  666  0.496997\n",
            "7         AM                1                         1    335  666  0.503003\n",
            "8         CF                0                         0     73   78  0.935897\n",
            "9         CF                0                         1      5   78  0.064103\n",
            "10        CF                1                         0     61   87  0.701149\n",
            "11        CF                1                         1     26   87  0.298851\n",
            "12        CM                0                         0    200  223  0.896861\n",
            "13        CM                0                         1     23  223  0.103139\n",
            "14        CM                1                         0    256  352  0.727273\n",
            "15        CM                1                         1     96  352  0.272727\n",
            "16        HF                0                         0     12   13  0.923077\n",
            "17        HF                0                         1      1   13  0.076923\n",
            "18        HF                1                         0     17   21  0.809524\n",
            "19        HF                1                         1      4   21  0.190476\n",
            "20        HM                0                         0     53   57  0.929825\n",
            "21        HM                0                         1      4   57  0.070175\n",
            "22        HM                1                         0     61   92  0.663043\n",
            "23        HM                1                         1     31   92  0.336957\n",
            "24        MF                0                         0     10   10  1.000000\n",
            "25        MF                1                         0     12   14  0.857143\n",
            "26        MF                1                         1      2   14  0.142857\n",
            "27        MM                0                         0     33   35  0.942857\n",
            "28        MM                0                         1      2   35  0.057143\n",
            "29        MM                1                         0     51   71  0.718310\n",
            "30        MM                1                         1     20   71  0.281690\n"
          ]
        }
      ],
      "source": [
        "# twin test for model\n",
        "\n",
        "df_count = df_test.groupby([\"sensitive\", \"c_charge_degree\", \"two_year_recid_predicted\"]).agg(\n",
        "    count=('sensitive', 'count')).reset_index()\n",
        "\n",
        "df_sum = df_count.groupby([\"sensitive\", \"c_charge_degree\"]).agg(\n",
        "    sum=('count', 'sum')).reset_index()\n",
        "\n",
        "df_summary = pd.merge(df_count, df_sum, on=[\"sensitive\", \"c_charge_degree\"])\n",
        "\n",
        "df_summary[\"prob\"] = df_summary[\"count\"] / df_summary[\"sum\"]\n",
        "print(df_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoqaUCVuP5Gh"
      },
      "source": [
        "Note! When looking at c_charge_degree we found that the model was more biased toward African-American males than Caucasian males (prediction for AM 0.5 vs. CM 0.27; in data AM 0.56 and CM 0.43)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "UyZCfYe8P5Gh",
        "outputId": "92636d17-1684-46ad-d5a2-7f6bc0fd0abc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sensitive\n",
              "AM    351\n",
              "CM    203\n",
              "CF     65\n",
              "AF     55\n",
              "HM     49\n",
              "MM     32\n",
              "HF     11\n",
              "MF      8\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sensitive</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AM</th>\n",
              "      <td>351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CM</th>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CF</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AF</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HM</th>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MM</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HF</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MF</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_test = df_test[df_test[\"two_year_recid_actual\"] != df_test['two_year_recid_predicted']]\n",
        "\n",
        "# samples misclassified, count by sensitive information\n",
        "df_test[\"sensitive\"].value_counts()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
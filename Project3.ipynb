{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3\n",
    "\n",
    "Dataset: COMPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7214, 53)\n",
      "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
      "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
      "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
      "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
      "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
      "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
      "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
      "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
      "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
      "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
      "       'decile_score.1', 'score_text', 'screening_date',\n",
      "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
      "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
      "       'start', 'end', 'event', 'two_year_recid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first fit a model predicting if the person will reoffend in the next two years. We could use a classifier for this. \n",
    "\n",
    "Next steps:\n",
    "\n",
    "* look at the data for bias\n",
    "* build a classifier\n",
    "\n",
    "Sensitive variables: race, sex \n",
    "\n",
    "Target variable: two_year_recid\n",
    "\n",
    "Features: age/age_cat, juv_fel_count, juv_misd_count, juv_other_count, priors_count, c_charge_degree, score_text, days_b_screening_arrest, decile_score, length_of_stay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twin test \n",
    "\n",
    "Feature: prior convictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annku\\AppData\\Local\\Temp\\ipykernel_10092\\3782434972.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"age_cat\"] = df[\"age_cat\"].replace({\"Less than 25\": 0, \"25 - 45\": 1, \"Greater than 45\": 2})\n"
     ]
    }
   ],
   "source": [
    "df = df[[\"race\", \"sex\", \"age_cat\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\", \"c_charge_degree\", \"two_year_recid\"]]\n",
    "\n",
    "df = df[(df[\"c_charge_degree\"] != 'O')]\n",
    "\n",
    "# sum 1-20 together\n",
    "df[\"juv_fel_count\"] = np.where(df[\"juv_fel_count\"] == 0, 0, 1)\n",
    "df[\"juv_misd_count\"] = np.where(df[\"juv_misd_count\"] == 0, 0, 1)\n",
    "df[\"juv_other_count\"] = np.where(df[\"juv_other_count\"] == 0, 0, 1)\n",
    "df[\"priors_count\"]\n",
    "\n",
    "df.loc[(df['priors_count'] >= 0) & (df['priors_count'] <= 10), 'priors_count'] = 0\n",
    "df.loc[(df['priors_count'] > 10) & (df['priors_count'] <= 20), 'priors_count'] = 1\n",
    "df.loc[(df['priors_count'] > 20), 'priors_count'] = 2\n",
    "\n",
    "df[\"c_charge_degree\"] = np.where(df[\"c_charge_degree\"] == \"M\", 0, 1)\n",
    "df[\"age_cat\"] = df[\"age_cat\"].replace({\"Less than 25\": 0, \"25 - 45\": 1, \"Greater than 45\": 2})\n",
    "df[\"race\"] = df[\"race\"].replace({\"Asian\": \"Minority\", \"Native American\": \"Minority\", \"Other\": \"Minority\"})\n",
    "\n",
    "df[\"sensitive\"] = df.apply(lambda x: x[\"race\"][0] + x[\"sex\"][0], axis=1)\n",
    "\n",
    "df.head()\n",
    "df.to_csv(\"data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensitive  priors_count  two_year_recid  count   sum      prob\n",
      "0         AF             0               0    396   616  0.642857\n",
      "1         AF             0               1    220   616  0.357143\n",
      "2         AF             1               0      9    29  0.310345\n",
      "3         AF             1               1     20    29  0.689655\n",
      "4         AF             2               1      7     7  1.000000\n",
      "5         AM             0               0   1278  2605  0.490595\n",
      "6         AM             0               1   1327  2605  0.509405\n",
      "7         AM             1               0     95   350  0.271429\n",
      "8         AM             1               1    255   350  0.728571\n",
      "9         AM             2               0     17    89  0.191011\n",
      "10        AM             2               1     72    89  0.808989\n",
      "11        CF             0               0    363   551  0.658802\n",
      "12        CF             0               1    188   551  0.341198\n",
      "13        CF             1               0      5    12  0.416667\n",
      "14        CF             1               1      7    12  0.583333\n",
      "15        CF             2               1      4     4  1.000000\n",
      "16        CM             0               0   1095  1791  0.611390\n",
      "17        CM             0               1    696  1791  0.388610\n",
      "18        CM             1               0     23    85  0.270588\n",
      "19        CM             1               1     62    85  0.729412\n",
      "20        CM             2               0      2    11  0.181818\n",
      "21        CM             2               1      9    11  0.818182\n",
      "22        HF             0               0     69   101  0.683168\n",
      "23        HF             0               1     32   101  0.316832\n",
      "24        HF             1               0      1     2  0.500000\n",
      "25        HF             1               1      1     2  0.500000\n",
      "26        HM             0               0    325   510  0.637255\n",
      "27        HM             0               1    185   510  0.362745\n",
      "28        HM             1               0     10    23  0.434783\n",
      "29        HM             1               1     13    23  0.565217\n",
      "30        HM             2               1      1     1  1.000000\n",
      "31        MF             0               0     54    72  0.750000\n",
      "32        MF             0               1     18    72  0.250000\n",
      "33        MF             1               1      1     1  1.000000\n",
      "34        MM             0               0    219   342  0.640351\n",
      "35        MM             0               1    123   342  0.359649\n",
      "36        MM             1               0      2     7  0.285714\n",
      "37        MM             1               1      5     7  0.714286\n",
      "38        MM             2               1      5     5  1.000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")\n",
    "\n",
    "df_count = df.groupby([\"sensitive\", \"priors_count\", \"two_year_recid\"]).agg(\n",
    "    count=('race', 'count')).reset_index()\n",
    "\n",
    "df_sum = df_count.groupby([\"sensitive\", \"priors_count\"]).agg(\n",
    "    sum=('count', 'sum')).reset_index()\n",
    "\n",
    "df_summary = pd.merge(df_count, df_sum, on=[\"sensitive\", \"priors_count\"])\n",
    "\n",
    "df_summary[\"prob\"] = df_summary[\"count\"] / df_summary[\"sum\"]\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group fairness\n",
    "\n",
    "only sensitive data as prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensitive  two_year_recid  count   sum      prob\n",
      "0         AF               0    405   652  0.621166\n",
      "1         AF               1    247   652  0.378834\n",
      "2         AM               0   1390  3044  0.456636\n",
      "3         AM               1   1654  3044  0.543364\n",
      "4         CF               0    368   567  0.649030\n",
      "5         CF               1    199   567  0.350970\n",
      "6         CM               0   1120  1887  0.593535\n",
      "7         CM               1    767  1887  0.406465\n",
      "8         HF               0     70   103  0.679612\n",
      "9         HF               1     33   103  0.320388\n",
      "10        HM               0    335   534  0.627341\n",
      "11        HM               1    199   534  0.372659\n",
      "12        MF               0     54    73  0.739726\n",
      "13        MF               1     19    73  0.260274\n",
      "14        MM               0    221   354  0.624294\n",
      "15        MM               1    133   354  0.375706\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")\n",
    "\n",
    "df_count = df.groupby([\"sensitive\", \"two_year_recid\"]).agg(\n",
    "    count=('race', 'count')).reset_index()\n",
    "\n",
    "df_sum = df_count.groupby([\"sensitive\"]).agg(\n",
    "    sum=('count', 'sum')).reset_index()\n",
    "\n",
    "df_summary = pd.merge(df_count, df_sum, on=[\"sensitive\"])\n",
    "\n",
    "df_summary[\"prob\"] = df_summary[\"count\"] / df_summary[\"sum\"]\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.72      1207\n",
      "           1       0.64      0.44      0.52       958\n",
      "\n",
      "    accuracy                           0.64      2165\n",
      "   macro avg       0.64      0.62      0.62      2165\n",
      "weighted avg       0.64      0.64      0.63      2165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")\n",
    "\n",
    "# Select relevant columns for features and target\n",
    "features = df.iloc[:, 3:-2]\n",
    "\n",
    "target = df['two_year_recid']\n",
    "\n",
    "# Handle missing values if any\n",
    "features = features.fillna(0)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
